{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6ba36b",
   "metadata": {},
   "source": [
    "# 01 â€” Single PDF Demo (OpenAI SDK â‰¥ 1.0)\n",
    "\n",
    "This notebook runs the **AI Paper Agent** pipeline on one PDF using the **new OpenAI Python SDK**.  \n",
    "Place this file in your repo at: `ai-paper-agent-starter/notebooks/01_single_pdf_demo.ipynb`.\n",
    "\n",
    "**What it does:**\n",
    "- Loads environment variables from `.env`\n",
    "- Processes a single PDF â†’ exports Markdown + JSON + CSV to `../outputs/`\n",
    "- Shows a preview of the generated Markdown and JSON\n",
    "- Includes an optional batch cell to process a whole folder of PDFs\n",
    "\n",
    "> Make sure you've updated `src/llm_extract.py` to the new SDK version and have `openai` â‰¥ 1.0 installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e41bd",
   "metadata": {},
   "source": [
    "## 0) Environment setup â€” load `.env` and confirm API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93108150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key present? True\n",
      "Model: gpt-4.1-mini\n",
      "Length: 164\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env at repo root (../.env relative to this notebook)\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "# Optional: set/override for this session only (uncomment and paste a key if needed)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "# os.environ[\"OPENAI_MODEL\"] = \"gpt-5-mini\"\n",
    "# os.environ[\"TEMPERATURE\"] = \"0.0\"\n",
    "\n",
    "# Sensible defaults if not set\n",
    "os.environ.setdefault(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
    "os.environ.setdefault(\"TEMPERATURE\", \"0.0\")\n",
    "\n",
    "print(\"API key present?\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "print(\"Model:\", os.getenv(\"OPENAI_MODEL\"))\n",
    "print(\"Length:\", len(os.getenv(\"OPENAI_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f30789e8-8cc7-4f52-8166-b57da84a5cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# does it work\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    project=os.getenv(\"OPENAI_PROJECT\")\n",
    ")\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=os.getenv(\"OPENAI_MODEL\"),\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say OK if the key + project ID works\"}],\n",
    "    max_completion_tokens=5,  # ðŸ‘ˆ updated\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f5483",
   "metadata": {},
   "source": [
    "## 1) Run the pipeline on **one** PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d13f4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'md': '../outputs\\\\summaries\\\\chatgpt_usuage.md',\n",
       " 'csv': '../outputs\\\\csv\\\\master_table.csv',\n",
       " 'json': '../outputs\\\\summaries\\\\chatgpt_usuage.json'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, json, pathlib\n",
    "sys.path.append(\"../\")  # allow `import src.*` from the notebook\n",
    "\n",
    "from src.batch import process_pdf\n",
    "\n",
    "# >>> EDIT THIS PATH to your own PDF inside ../data/...\n",
    "pdf = \"../data/my_papers/chatgpt_usuage.pdf\"\n",
    "# Example: pdf = \"../data/my_papers/MyArticle.pdf\"\n",
    "\n",
    "out_dir = \"../outputs\"\n",
    "result = process_pdf(pdf, out_dir)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44130f12",
   "metadata": {},
   "source": [
    "## 2) Preview the generated Markdown (first ~2000 chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d5ca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Article Summary\n",
      "\n",
      "**Citation:** Bick et al., \"The Rapid Adoption of Generative AI,\" National Bureau of Economic Research, 2024.\n",
      "\n",
      "---\n",
      "### 1) What is it about â€” Main questions\n",
      "How is ChatGPT used by consumers globally and what are the patterns of usage by topic, intent, and demographics? _(pp. 1, 2, 11, 12, 25, 27, 33)_\n",
      "\n",
      "### 1) Purpose / aim\n",
      "To document the rapid growth, usage patterns, and demographic characteristics of ChatGPT users globally while preserving user privacy. _(pp. 1, 3, 5, 6)_\n",
      "\n",
      "### 1) Theory / key concepts\n",
      "ChatGPT likely improves worker output by providing decision support, particularly in knowledge-intensive jobs where productivity depends on decision quality. _(pp. 3, 35)_\n",
      "\n",
      "### 2) Methods â€” Research design\n",
      "Large-scale observational study using a privacy-preserving automated classification pipeline to analyze user messages and demographics from ChatGPT consumer plans between May 2024 and July 2025. _(pp. 3, 5, 6)_\n",
      "\n",
      "### 2) Methods â€” Data sources\n",
      "Data includes total daily message volumes, randomly sampled de-identified user messages, and aggregated employment and education data accessed via a secure Data Clean Room. _(pp. 5, 6)_\n",
      "\n",
      "### 2) Methods â€” Sample/participants\n",
      "Approximately 1.1 million randomly sampled conversations from ChatGPT Free, Plus, and Pro users over May 2024 to June 2025, with additional samples for demographic analysis involving ~130,000 users. _(pp. 5, 6)_\n",
      "\n",
      "### 2) Methods â€” Instruments/tools\n",
      "Automated large language model classifiers deployed with privacy filters to categorize messages by work-relatedness, topic, intent (Asking, Doing, Expressing), and job-related intermediate work activities (O*NET IWAs). _(pp. 7, 11, 50)_\n",
      "\n",
      "### 3) Analysis â€” Type\n",
      "Descriptive and inferential analysis combining message classification frequencies with demographic regressions and validation against human annotations. _(pp. 3, 5, 27, 50)_\n",
      "\n",
      "### 3) Analysis â€” Techniques/frameworks\n",
      "Large Language Model-based text classification with prompt engineering, weigh\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# show first ~2000 characters from the Markdown output\n",
    "md_text = Path(result['md']).read_text(encoding='utf-8')\n",
    "print(md_text[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4cea33-bcb9-4ec9-bb06-cadd10f0cc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Article Summary\n",
       "\n",
       "**Citation:** Bick et al., \"The Rapid Adoption of Generative AI,\" National Bureau of Economic Research, 2024.\n",
       "\n",
       "---\n",
       "### 1) What is it about â€” Main questions\n",
       "How is ChatGPT used by consumers globally and what are the patterns of usage by topic, intent, and demographics? _(pp. 1, 2, 11, 12, 25, 27, 33)_\n",
       "\n",
       "### 1) Purpose / aim\n",
       "To document the rapid growth, usage patterns, and demographic characteristics of ChatGPT users globally while preserving user privacy. _(pp. 1, 3, 5, 6)_\n",
       "\n",
       "### 1) Theory / key concepts\n",
       "ChatGPT likely improves worker output by providing decision support, particularly in knowledge-intensive jobs where productivity depends on decision quality. _(pp. 3, 35)_\n",
       "\n",
       "### 2) Methods â€” Research design\n",
       "Large-scale observational study using a privacy-preserving automated classification pipeline to analyze user messages and demographics from ChatGPT consumer plans between May 2024 and July 2025. _(pp. 3, 5, 6)_\n",
       "\n",
       "### 2) Methods â€” Data sources\n",
       "Data includes total daily message volumes, randomly sampled de-identified user messages, and aggregated employment and education data accessed via a secure Data Clean Room. _(pp. 5, 6)_\n",
       "\n",
       "### 2) Methods â€” Sample/participants\n",
       "Approximately 1.1 million randomly sampled conversations from ChatGPT Free, Plus, and Pro users over May 2024 to June 2025, with additional samples for demographic analysis involving ~130,000 users. _(pp. 5, 6)_\n",
       "\n",
       "### 2) Methods â€” Instruments/tools\n",
       "Automated large language model classifiers deployed with privacy filters to categorize messages by work-relatedness, topic, intent (Asking, Doing, Expressing), and job-related intermediate work activities (O*NET IWAs). _(pp. 7, 11, 50)_\n",
       "\n",
       "### 3) Analysis â€” Type\n",
       "Descriptive and inferential analysis combining message classification frequencies with demographic regressions and validation against human annotations. _(pp. 3, 5, 27, 50)_\n",
       "\n",
       "### 3) Analysis â€” Techniques/frameworks\n",
       "Large Language Model-based text classification with prompt engineering, weighting to adjust for sampling, regression modeling to study demographic effects, and validation against human-coded datasets. _(pp. 5, 6, 27, 50)_\n",
       "\n",
       "### 3) Analysis â€” Validation/reliability\n",
       "Classifier outputs were validated by comparing with human annotations on the WildChat dataset, showing substantial agreement for most categories, with details provided on agreement statistics and biases. _(pp. 50, 51, 52, 53, 56)_\n",
       "\n",
       "### 4) Results â€” Core findings\n",
       "ChatGPT usage grew rapidly to 700 million weekly active users by July 2025. Non-work queries dominate (73% by June 2025). Most common conversation topics are Practical Guidance, Writing, and Seeking Information (77% combined). Gender gaps closed, with roughly equal male and female users. Younger users dominate, with nearly half under age 26. Work-related usage more common among educated users and high-paid professional occupations. Writing is the most prevalent work task (42%), mostly editing/modifying text. User intent classification finds 49% Asking, 40% Doing, and 11% Expressing. O*NET mapping indicates most work-related uses involve information processing and decision-making tasks. Interaction quality tends to be higher for Asking messages. _(pp. 1, 2, 3, 11, 12, 16, 17, 18, 19, 20, 25, 27, 33, 35)_\n",
       "\n",
       "### 4) Results â€” Surprising results\n",
       "The share of programming-related queries is low (4.2%), contrasting with other chatbot studies. Social-emotional or companionship queries are rare (under 2%). Gender gap in usage has narrowed dramatically over time, reversing initial male dominance. _(pp. 2, 3, 25, 26)_\n",
       "\n",
       "### 4) Results â€” Contributions\n",
       "Provides the first large-scale, privacy-preserving, internal analysis of ChatGPT usage globally. Develops novel classification taxonomies and links usage with rich demographic data. Identifies non-work applications' rapid growth and the predominance of decision support and writing tasks at work. Documents demographic shifts in usage patterns. _(pp. 1, 3, 5, 25, 27, 33)_\n",
       "\n",
       "### 4) Results â€” Limitations\n",
       "Data excludes non-consumer ChatGPT plans and logged-out users in early periods. Employment and education data limited to a subset of users and aggregated. Classifications rely on automated classifiers which, despite validation, have inherent uncertainty and potential misclassification biases. _(pp. 6, 27, 50)_\n",
       "\n",
       "### 5) Future â€” Gaps\n",
       "Need for further research on long-term economic impacts, generalizability beyond consumer plans, and detailed occupational adoption mechanisms. Analysis of corporate and educational plan users is missing. Improved classifier precision and ground truth validation could be enhanced. _(pp. 35)_\n",
       "\n",
       "### 5) Future â€” Extensions\n",
       "Extensions could include linking ChatGPT usage to productivity outcomes, exploring usage in developing countries more deeply, and evaluating interventions to increase adoption in underrepresented groups. _(pp. 35)_\n",
       "\n",
       "### 5) Future â€” Your ideas\n",
       "Suggest studying the causal impact of ChatGPT usage on individual and firm-level productivity, including decision quality measures. Develop finer-grained intent taxonomies to capture emerging use cases. Investigate longitudinal user behavior changes. _(pp. 35)_\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968d868",
   "metadata": {},
   "source": [
    "## 3) Inspect JSON output (keys + example evidence pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3cebb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['citation',\n",
       "  'about_main_questions',\n",
       "  'about_purpose',\n",
       "  'about_theory',\n",
       "  'methods_design',\n",
       "  'methods_data_sources',\n",
       "  'methods_sample',\n",
       "  'methods_instruments',\n",
       "  'analysis_type',\n",
       "  'analysis_techniques',\n",
       "  'analysis_validation',\n",
       "  'results_core',\n",
       "  'results_surprising',\n",
       "  'results_contributions',\n",
       "  'results_limitations',\n",
       "  'future_gaps',\n",
       "  'future_extensions',\n",
       "  'future_your_ideas',\n",
       "  'raw_sections',\n",
       "  'raw_llm_json'],\n",
       " [1, 2, 3, 11, 12, 16, 17, 18, 19, 20, 25, 27, 33, 35])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, pathlib\n",
    "data = json.loads(pathlib.Path(result['json']).read_text(encoding='utf-8'))\n",
    "list(data.keys()), data.get(\"results_core\", {}).get(\"evidence_pages\", [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30653256",
   "metadata": {},
   "source": [
    "## 4) (Optional) Batch process all PDFs in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8937cf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PDFs: ['chatgpt_usuage.pdf']\n",
      "Processing: chatgpt_usuage.pdf\n",
      "\n",
      "Wrote:\n",
      " - ../outputs\\summaries\\chatgpt_usuage.md\n"
     ]
    }
   ],
   "source": [
    "import os, glob, sys\n",
    "sys.path.append(\"../\")\n",
    "from src.batch import process_pdf\n",
    "\n",
    "in_dir = \"../data/my_papers\"   # change this to your folder\n",
    "out_dir = \"../outputs\"\n",
    "\n",
    "pdfs = sorted(glob.glob(os.path.join(in_dir, \"*.pdf\")))\n",
    "print(\"Found PDFs:\", [os.path.basename(p) for p in pdfs])\n",
    "\n",
    "all_results = []\n",
    "for p in pdfs:\n",
    "    print(\"Processing:\", os.path.basename(p))\n",
    "    all_results.append(process_pdf(p, out_dir))\n",
    "\n",
    "print(\"\\nWrote:\")\n",
    "for r in all_results:\n",
    "    print(\" -\", r[\"md\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa00eea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Notes & Troubleshooting\n",
    "\n",
    "- If the summary is empty, check that the **API key is present** in the first cell. You should see `API key present? True`.\n",
    "- If your PDF has **no selectable text** (a scanned image), the current parser will extract little or nothing. We can add OCR later.\n",
    "- Always open the Markdown files in **VS Code** to avoid Windows encoding issues.\n",
    "- Outputs go to `../outputs/summaries/` (Markdown + JSON) and `../outputs/csv/master_table.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
